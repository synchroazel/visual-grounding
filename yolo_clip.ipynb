{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using MPS.\n"
     ]
    }
   ],
   "source": [
    "#@title Import necessary packages and set correct device\n",
    "\n",
    "#  To use venv,\n",
    "#  python -m ipykernel install --user --name=yoloenv\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from modules.utilities import visual_grounding_test\n",
    "\n",
    "from modules.refcocog import RefCOCOg, RefCOCOgSample\n",
    "from modules.yoloclip import YoloClip\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # CUDA GPU\n",
    "    print(\"[INFO] Using GPU.\")\n",
    "elif torch.has_mps:\n",
    "    device = torch.device(\"mps\")  # Apple Silicon GPU\n",
    "    print(\"[INFO] Using MPS.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"[INFO] No GPU found, using CPU instead.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-27T13:12:43.544932Z",
     "end_time": "2023-05-27T13:12:59.551537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset Size: 49822\n",
      "[INFO] train split:  42226\n",
      "[INFO] val split:    2573\n",
      "[INFO] test split:   5023\n"
     ]
    }
   ],
   "source": [
    "#@title Import RefCOCOg dataset and its train/val/test splits\n",
    "\n",
    "# data_path = \"/media/dmmp/vid+backup/Data/refcocog\"\n",
    "data_path = \"dataset/refcocog\"\n",
    "\n",
    "dataset = RefCOCOg(ds_path=data_path)\n",
    "\n",
    "train_ds = RefCOCOg(ds_path=data_path, split='train')\n",
    "val_ds = RefCOCOg(ds_path=data_path, split='val')\n",
    "test_ds = RefCOCOg(ds_path=data_path, split='test')\n",
    "\n",
    "print(f\"[INFO] Dataset Size: {len(dataset)}\")\n",
    "print(f\"[INFO] train split:  {len(train_ds)}\")\n",
    "print(f\"[INFO] val split:    {len(val_ds)}\")\n",
    "print(f\"[INFO] test split:   {len(test_ds)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-27T13:12:59.553466Z",
     "end_time": "2023-05-27T13:13:10.763961Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time elapsed: 0.50s\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'IoU': 0.7288451790809631,\n 'cosine': 0.31918758153915405,\n 'euclidean': 1.166886806488037,\n 'dotproduct': 5.456388473510742,\n 'grounding': 0.0}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Initialize YoloClip pipeline\n",
    "\n",
    "yoloclip = YoloClip(device=\"mps\", categories=dataset.categories)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-27T13:25:53.671798Z",
     "end_time": "2023-05-27T13:25:54.248546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 3227.7ms pre-process, 66.1ms inference, 0.6ms NMS per image at shape (1, 3, 384, 640)\n",
      "Saved 1 image to \u001B[1mruns/detect/exp\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "         xmin        ymin         xmax        ymax  confidence  class    name\n0  743.290344   48.343597  1141.756714  720.000000    0.879861      0  person\n1  441.989624  437.336670   496.585083  710.036255    0.675118     27     tie\n2  123.050964  193.238068   714.690674  719.771362    0.666693      0  person\n3  978.989807  313.579468  1025.302734  415.526184    0.261517     27     tie",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n      <th>confidence</th>\n      <th>class</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>743.290344</td>\n      <td>48.343597</td>\n      <td>1141.756714</td>\n      <td>720.000000</td>\n      <td>0.879861</td>\n      <td>0</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>441.989624</td>\n      <td>437.336670</td>\n      <td>496.585083</td>\n      <td>710.036255</td>\n      <td>0.675118</td>\n      <td>27</td>\n      <td>tie</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>123.050964</td>\n      <td>193.238068</td>\n      <td>714.690674</td>\n      <td>719.771362</td>\n      <td>0.666693</td>\n      <td>0</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>978.989807</td>\n      <td>313.579468</td>\n      <td>1025.302734</td>\n      <td>415.526184</td>\n      <td>0.261517</td>\n      <td>27</td>\n      <td>tie</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/azel/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-5-9 Python-3.9.6 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31m\u001B[1mrequirements:\u001B[0m /Users/azel/.cache/torch/hub/requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 10613.9ms pre-process, 60.2ms inference, 0.5ms NMS per image at shape (1, 3, 384, 640)\n",
      "Saved 1 image to \u001B[1mruns/detect/exp2\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "         xmin        ymin         xmax        ymax  confidence  class    name\n0  743.290344   48.343597  1141.756714  720.000000    0.879861      0  person\n1  441.989624  437.336670   496.585083  710.036255    0.675118     27     tie\n2  123.050964  193.238068   714.690674  719.771362    0.666693      0  person\n3  978.989807  313.579468  1025.302734  415.526184    0.261517     27     tie",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n      <th>confidence</th>\n      <th>class</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>743.290344</td>\n      <td>48.343597</td>\n      <td>1141.756714</td>\n      <td>720.000000</td>\n      <td>0.879861</td>\n      <td>0</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>441.989624</td>\n      <td>437.336670</td>\n      <td>496.585083</td>\n      <td>710.036255</td>\n      <td>0.675118</td>\n      <td>27</td>\n      <td>tie</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>123.050964</td>\n      <td>193.238068</td>\n      <td>714.690674</td>\n      <td>719.771362</td>\n      <td>0.666693</td>\n      <td>0</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>978.989807</td>\n      <td>313.579468</td>\n      <td>1025.302734</td>\n      <td>415.526184</td>\n      <td>0.261517</td>\n      <td>27</td>\n      <td>tie</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@tile Test YoloClip on a random sample\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "idx = np.random.randint(0, len(dataset))\n",
    "\n",
    "sample = RefCOCOgSample(**dataset[idx])\n",
    "\n",
    "for sentence in sample.sentences:\n",
    "    yoloclip(sample, sentence, show=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-27T13:04:53.869737Z",
     "end_time": "2023-05-27T13:05:06.328518Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Execute testing on the test dataset\n",
    "\n",
    "visual_grounding_test(yoloclip, test_ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
